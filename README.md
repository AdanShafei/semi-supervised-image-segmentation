# Semi-Supervised Image Segmentation with ResNet-18 and Pseudo-Labeling

This project builds a **semi-supervised image segmentation pipeline** that classifies and segments satellite imagery using a limited amount of labeled data and a large set of unlabeled samples.

The model integrates **ResNet-18** as a feature encoder, **Dice + Binary Cross-Entropy loss**, and **pseudo-labeling** to leverage unlabeled data effectively. The approach achieved a **mean IoU of â‰ˆ 0.46** on a held-out test set.

---

## ğŸŒ Project Overview
- **Goal:** Predict binary segmentation masks for satellite images.  
- **Challenge:** Only a small portion of the dataset is labeled; most images are unlabeled.  
- **Solution:** A semi-supervised training pipeline that iteratively generates and refines pseudo-labels to improve performance.  
- **Metric:** Mean Intersection-over-Union (mIoU).  

---

## ğŸ§  Methodology

### 1ï¸âƒ£ Architecture
- **Backbone:** ResNet-18 pretrained on ImageNet  
- **Decoder:** Lightweight up-sampling head with 1Ã—1 convolution + sigmoid  
- **Loss:** Combined **Dice Loss + Binary Cross-Entropy (BCE)**  
- **Optimizer:** AdamW; **Scheduler:** ReduceLROnPlateau

### 2ï¸âƒ£ Semi-Supervised Training Pipeline
1. **Supervised Warm-Up** â€“ Train on the small labeled set.  
2. **Pseudo-Label Generation** â€“ Predict masks on unlabeled data; keep high-confidence predictions.  
3. **Joint Training** â€“ Train on (labeled + pseudo-labeled) together.  
4. **Fine-Tuning** â€“ Retrain on labeled data only to denoise.

### 3ï¸âƒ£ Data Augmentation
Random flips/rotations, color jitter, normalization (ImageNet mean/std), random crops/resizing.

### 4ï¸âƒ£ Inference
**Test-Time Augmentation (TTA)** with flips/rotations and prediction averaging. Threshold = 0.5.

---

## ğŸ“Š Results

| Phase | Description | mIoU (Validation) |
|:------|:------------|:-----------------:|
| Supervised Baseline | Labeled data only | 0.37 |
| + Pseudo-Labeling   | Add confident unlabeled | 0.43 |
| Final (+ TTA)       | Fine-tuned & averaged | **0.46** |

> Pseudo-labeling improved validation mIoU by roughly **+0.09** over the baseline.

---

## ğŸ“‚ Repository Structure
<pre><code>.
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ Semi-Supervised_Project.ipynb      # full training + inference notebook
â”œâ”€â”€ submission/
â”‚   â””â”€â”€ submission.csv                  # final predictions (competition format)
â”œâ”€â”€ Projec_Report.pdf           # detailed methodology & results
â””â”€â”€ README.md
</code></pre>

---

## â–¶ï¸ How to Run

### Option 1 â€” Google Colab
Upload the notebook and run cell-by-cell.  
Ensure the dataset directories are accessible in your environment (Drive/Kaggle):  
`train-semi/`, `train-semi-segmentation/`, `unlabeled/`, `test/`.

### Option 2 â€” Local (with GPU)
```bash
jupyter notebook notebooks/CSE164_Final_Project.ipynb
